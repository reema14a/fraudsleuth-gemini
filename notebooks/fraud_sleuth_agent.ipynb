{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **FraudSleuth Gen AI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# LLM + LangChain\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.api_core import retry\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.agents import initialize_agent, Tool, AgentType\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "# ChromaDB\n",
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "\n",
    "# Requests for Fraud API\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example .env usage (you can inline if needed)\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "FRAUD_API_KEY = os.getenv(\"FRAUD_API_KEY\")\n",
    "\n",
    "GENAI_MODEL=\"gemini-2.0-flash\"\n",
    "EMBEDDING_MODEL = \"models/embedding-001\"\n",
    "CHROMA_COLLECTION_NAME = \"fraud_docs\"\n",
    "\n",
    "FRAUD_API_URL = \"https://ipqualityscore.com/api/json/ip/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate Gemini\n",
    "client = genai.Client(api_key = GEMINI_API_KEY)\n",
    "\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "genai.models.Models.generate_content = retry.Retry(\n",
    "    predicate=is_retriable)(genai.models.Models.generate_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Embedding Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "    # Specify whether to generate embeddings for documents, or queries\n",
    "    def __init__(self, document_mode=True):\n",
    "        self.document_mode = document_mode\n",
    "\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        if self.document_mode:\n",
    "            embedding_task = \"retrieval_document\"\n",
    "        else:\n",
    "            embedding_task = \"retrieval_query\"\n",
    "\n",
    "        \n",
    "        response = client.models.embed_content(\n",
    "                                    model = EMBEDDING_MODEL,\n",
    "                                    contents = input,\n",
    "                                    config = types.EmbedContentConfig(\n",
    "                                        task_type = embedding_task,\n",
    "                                    )\n",
    "                                )\n",
    "        \n",
    "        # Return list of embedding vectors\n",
    "        return [e.values for e in response.embeddings]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Chroma Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChromaVectorSearch:\n",
    "\n",
    "    def __init__(self, persist_directory=\"chroma_db\", collection_name = CHROMA_COLLECTION_NAME):\n",
    "        \n",
    "        self.persist_directory = persist_directory\n",
    "        self.collection_name = collection_name\n",
    "        self.client = chromadb.PersistentClient(path = self.persist_directory)\n",
    "        self.embed_fn = GeminiEmbeddingFunction(document_mode = True)\n",
    "    \n",
    "        # Create or get collection\n",
    "        self.collection = self.client.get_or_create_collection(name = self.collection_name,\n",
    "                                                               embedding_function = self.embed_fn)\n",
    "        \n",
    "        self.load_documents_from_file(\"data/knowledge_base.txt\")\n",
    "\n",
    "    def load_documents_from_file(self, file_path: str):\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, \"r\") as f:\n",
    "                docs = [line.strip() for line in f if line.strip()]\n",
    "                self.add_documents(docs)\n",
    "                print(f\"✅ Loaded {len(docs)} documents from {file_path} into ChromaDB.\")\n",
    "        else:\n",
    "            print(f\"⚠️ File not found: {file_path}\")\n",
    "\n",
    "    def add_documents(self, documents: list[str], ids: list[str] = None):\n",
    "        \"\"\"\n",
    "        Adds documents to ChromaDB with embeddings.\n",
    "        \"\"\"\n",
    "        if not documents:\n",
    "            print(\"⚠️ No documents to add.\")\n",
    "            return\n",
    "        if ids is None:\n",
    "            ids = [str(i) for i in range(len(documents))]\n",
    "        self.collection.add(documents = documents, ids = ids)\n",
    "\n",
    "    def query(self, text: str, n_results: int = 5):\n",
    "        \"\"\"\n",
    "        Queries the collection for top matching documents.\n",
    "        \"\"\"\n",
    "\n",
    "        results = self.collection.query(query_texts=[text], n_results = n_results)\n",
    "        return results\n",
    "\n",
    "    def reset_collection(self):\n",
    "        self.client.delete_collection(self.collection_name)\n",
    "        self.collection = self.client.get_or_create_collection(name = self.collection_name, \n",
    "                                                               embedding_function = self.embed_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fraud Detection API Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudChecker:\n",
    "    def __init__(self):\n",
    "        self.api_key = FRAUD_API_KEY\n",
    "        self.api_url = FRAUD_API_URL\n",
    "\n",
    "    def check_ip(self, ip: str) -> str:\n",
    "        try:\n",
    "            url = f\"{self.api_url}{self.api_key}/{ip}\"\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                return f\"Fraud Score: {data.get('fraud_score')}, VPN: {data.get('vpn')},\"\\\n",
    "                       f\" Proxy: {data.get('proxy')}, Tor: {data.get('tor')},\"\\\n",
    "                       f\" Crawler: {data.get('crawler')}, Recent Abuse: {data.get('recent_abuse')},\"\\\n",
    "                       f\" Bot: {data.get('is_bot')}\"\n",
    "            else:\n",
    "                return f\"Error from API: {response.status_code}\"\n",
    "        except Exception as e:\n",
    "            return f\"Exception during fraud check: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LangChain Prompt Template and Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template to synthesize context and external API result\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"query\", \"retrieved_docs\", \"fraud_api_result\"],\n",
    "    template=\"\"\"\n",
    "        You are a fraud analysis assistant.\n",
    "\n",
    "        User Query:\n",
    "        {query}\n",
    "\n",
    "        Retrieved Knowledge Context:\n",
    "        {retrieved_docs}\n",
    "\n",
    "        Fraud Check Result (if applicable):\n",
    "        {fraud_api_result}\n",
    "\n",
    "        Based on all of the above, provide a clear and actionable response to the user.\n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "# Set up LangChain Gemini Chat model\n",
    "llm = ChatGoogleGenerativeAI(model = GENAI_MODEL, temperature = 0.2, google_api_key = GEMINI_API_KEY)\n",
    "llm_chain = prompt_template | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Tool Definition and Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ File not found: data/knowledge_base.txt\n"
     ]
    }
   ],
   "source": [
    "# Initialize tools\n",
    "fraud_checker = FraudChecker()\n",
    "vector_search = ChromaVectorSearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ip_or_email(query: str):\n",
    "    \"\"\"Basic regex utility to extract IPs or emails from a query.\"\"\"\n",
    "    ip_match = re.search(r'\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b', query)\n",
    "    email_match = re.search(r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w{2,4}\\b', query)\n",
    "    return ip_match.group(0) if ip_match else email_match.group(0) if email_match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_tool(query: str) -> str:\n",
    "    # 1. Get vector search results\n",
    "    vector_results = vector_search.query(query)\n",
    "    retrieved_docs = \"\\n\".join(vector_results[\"documents\"][0])\n",
    "\n",
    "    # 2. If IP or email found, call fraud API\n",
    "    suspicious_input = extract_ip_or_email(query)\n",
    "    fraud_api_result = \"\"\n",
    "    if suspicious_input:\n",
    "        fraud_api_result = fraud_checker.check_ip(suspicious_input)\n",
    "    else:\n",
    "        fraud_api_result = \"No IP or email detected in query.\"\n",
    "\n",
    "    # 3. Run final prompt\n",
    "    return llm_chain.invoke({\n",
    "            \"query\": query,\n",
    "            \"retrieved_docs\": retrieved_docs,\n",
    "            \"fraud_api_result\": fraud_api_result\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unified tool\n",
    "combined_fraud_tool = Tool(\n",
    "    name=\"FraudKnowledgeAndCheckTool\",\n",
    "    func=combined_tool,\n",
    "    description=\"Use this to handle any query involving fraud detection, signs of fraud, or suspicious IP/email lookup.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s9/jq10pq213hvgwhd8sxxh3lsc0000gn/T/ipykernel_33770/3932163715.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key = \"chat_history\", return_messages = True)\n",
      "/var/folders/s9/jq10pq213hvgwhd8sxxh3lsc0000gn/T/ipykernel_33770/3932163715.py:5: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  fraud_agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "# Memory for conversation context\n",
    "memory = ConversationBufferMemory(memory_key = \"chat_history\", return_messages = True)\n",
    "\n",
    "# Initialize the agent\n",
    "fraud_agent = initialize_agent(\n",
    "    tools = [combined_fraud_tool],\n",
    "    llm = llm,\n",
    "    agent = AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory = memory,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"FraudKnowledgeAndCheckTool\",\n",
      "    \"action_input\": \"198.51.100.23\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mcontent=\"Based on the information provided, the IP address 198.51.100.23 appears to be safe.\\n\\n**Here's a summary:**\\n\\n*   **Fraud Score: 0** - Indicates a very low risk of fraudulent activity associated with this IP address.\\n*   **VPN: False, Proxy: False, Tor: False** - The IP address is not associated with VPNs, proxies, or the Tor network, which are often used to mask IP addresses.\\n*   **Crawler: None, Bot: None** - The IP address is not associated with known web crawlers or bots.\\n*   **Recent Abuse: False** - There's no recent history of abuse linked to this IP address.\\n\\n**Actionable Response:**\\n\\nYou can likely proceed with interactions involving this IP address with a high degree of confidence. The analysis suggests it's a legitimate user or server.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run-a251428b-2367-4e03-82cc-4e68e9cc02fe-0' usage_metadata={'input_tokens': 99, 'output_tokens': 192, 'total_tokens': 291, 'input_token_details': {'cache_read': 0}}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The IP address 198.51.100.23 appears to be safe. It has a very low risk of fraudulent activity, is not associated with VPNs, proxies, or the Tor network, and has no recent history of abuse. It is likely a legitimate user or server.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The IP address 198.51.100.23 appears to be safe. It has a very low risk of fraudulent activity, is not associated with VPNs, proxies, or the Tor network, and has no recent history of abuse. It is likely a legitimate user or server.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_agent.run(\"What can you tell me about this IP: 198.51.100.23? Is it suspicious?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraudAgent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
